{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn import mixture\n",
    "from sklearn import metrics\n",
    "import sys\n",
    "from scipy import stats\n",
    "from pdb import set_trace\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepareTrainSetRec():\n",
    "    '''Each time the train data are loaded, all the features are calculated as the test set\n",
    "    '''\n",
    "    data = pd.read_csv('labeled_sina.csv')\n",
    "    dp = DataPrep()\n",
    "    allorder = dp.computeEWAVBackward(data)\n",
    "    hmmdata = dp.HMMPrep(allorder.copy())\n",
    "    \n",
    "    hmmdata['state']=0\n",
    "    hmmdata.loc[(hmmdata['side']=='B')&(hmmdata['IsSpoof']==False),'state'] = 0\n",
    "    hmmdata.loc[(hmmdata['side']=='S')&(hmmdata['IsSpoof']==False),'state'] = 1\n",
    "    hmmdata.loc[(hmmdata['side']=='B')&(hmmdata['IsSpoof']==True),'state'] = 2\n",
    "    hmmdata.loc[(hmmdata['side']=='S')&(hmmdata['IsSpoof']==True),'state'] = 3\n",
    "    return hmmdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def toMS(x):\n",
    "    return ((x.hour*60+x.minute)*60+x.second)*1000000+x.microsecond\n",
    "def timeDelta2MS(x):\n",
    "    return (((x.hours*60+x.minutes)*60+x.seconds)*1000+x.milliseconds)*1000+x.microseconds\n",
    "    \n",
    "class DataPrep:\n",
    "    ''' The parameters:\n",
    "    1. isLean: whether we are dealing with data with more information. isLean=False, we have a richer data like the Training set. isLean=True, we have a lean data --only brief summary for each order\n",
    "    2. decay_factor: a multiple of T_M (median trading gap)\n",
    "    3. linger_factor: this is the multiple of the median trading gap. With this parameter, we will ignore all ordrers placed linger_factor*T_M ago\n",
    "    '''\n",
    "    def __init__(self,isLean=False,linger_factor = 40,decay_factor=5):        \n",
    "        self.isLean = isLean\n",
    "        self.linger_factor = linger_factor\n",
    "        self.decay_factor = decay_factor\n",
    "        self.medianT = 0 #the median of the trade interval\n",
    "        \n",
    "    def processDatafile(self,filename):\n",
    "        data = pd.read_csv(filename)\n",
    "        return self.processData(data)\n",
    "    \n",
    "    def processData(self,data,verbose=1):\n",
    "        if verbose>0:\n",
    "            print '----Data cleaning----'\n",
    "        if self.isLean: \n",
    "            allorder = self.cleanDataLean(data)\n",
    "        else:\n",
    "            allorder = self.cleanData(data)\n",
    "\n",
    "        data = self.prepare(allorder)\n",
    "        \n",
    "        if verbose>0:\n",
    "            print '---- Feature calculation----'\n",
    "    \n",
    "        allorder = self.computeEWAVBackward(data)\n",
    "     \n",
    "        \n",
    "        if verbose>0:\n",
    "            print '----- Prepare for HMM------'\n",
    "        data = self.HMMPrep(allorder.copy())\n",
    "        \n",
    "        return allorder,data\n",
    "    \n",
    "    def computeEWAVBackward(self,data):\n",
    "        \n",
    "        if len(data)<2:\n",
    "            raise ValueError('data too short')\n",
    "    \n",
    "        data['time diff'] = data['time diff'].fillna(24*3600*1000000)\n",
    "        self.medianT = np.median(data['time diff'])\n",
    "        T = self.medianT*self.decay_factor\n",
    "        linger = self.medianT*self.linger_factor\n",
    "        epsilon = sys.float_info.epsilon\n",
    "        \n",
    "        data['ewav_back canc buy'] = epsilon\n",
    "        data['ewav_back canc sell'] = epsilon\n",
    "        data['ewav_back exec buy'] = epsilon\n",
    "        data['ewav_back exec sell'] = epsilon\n",
    "        \n",
    "        set_trace()\n",
    "    \n",
    "        for ii in range(1,len(data)):\n",
    "            coef = math.exp(-data.at[ii,'time diff']/T) if data.at[ii,'time diff']<=linger else 0\n",
    "            set_trace()\n",
    "            data.loc[ii,'ewav_back canc buy'] = data.loc[ii,'cancelled buy']+data.loc[ii-1,'ewav_back canc buy']*coef\n",
    "            data.loc[ii,'ewav_back canc sell'] = data.loc[ii,'cancelled sell']+data.loc[ii-1,'ewav_back canc sell']*coef\n",
    "            data.loc[ii,'ewav_back exec buy'] = data.loc[ii,'exec buy']+data.loc[ii-1,'ewav_back exec buy']*coef\n",
    "            data.loc[ii,'ewav_back exec sell'] = data.loc[ii,'exec sell']+data.loc[ii-1,'ewav_back exec sell']*coef\n",
    "            set_trace()\n",
    "        ff = lambda x:x if x>epsilon else epsilon\n",
    "        data['ewav_back canc buy'] = data['ewav_back canc buy'].map(ff)\n",
    "        data['ewav_back canc sell'] = data['ewav_back canc sell'].map(ff)\n",
    "        data['ewav_back exec buy'] = data['ewav_back exec buy'].map(ff)\n",
    "        data['ewav_back exec sell'] = data['ewav_back exec sell'].map(ff)\n",
    "      \n",
    "        data['ewav_back buy/sell'] = data['ewav_back canc buy']/data['ewav_back canc sell'] \n",
    "        data['log ewav_back buy/sell'] = data['ewav_back buy/sell'].map(math.log)\n",
    "        data['ewav_back sell/buy'] = data['ewav_back canc sell']/data['ewav_back canc buy']\n",
    "                \n",
    "        data['ewav_back buy exec+canc'] = data['ewav_back exec buy'] + data['ewav_back canc buy']\n",
    "        data['ewav_back buy exec/total']=  data['ewav_back exec buy']/data['ewav_back buy exec+canc']       \n",
    "       \n",
    "        data['ewav_back sell exec+canc'] = data['ewav_back exec sell'] + data['ewav_back canc sell']\n",
    "        data['ewav_back sell exec/total'] = data['ewav_back exec sell']/data['ewav_back sell exec+canc']\n",
    "    \n",
    "        return data\n",
    "    \n",
    "    def cleanDataLean(self,data):\n",
    "        #data['q_exec'].fillna(0,inplace=True)\n",
    "        data['q_exec'].fillna(0,inplace=True)\n",
    "        data['execution_time'] = data['execution_time'].map(lambda x:pd.to_datetime(x))\n",
    "        data['cancel_entry_time'] = data['cancel_entry_time'].map(lambda x:pd.to_datetime(x))\n",
    "        data['order_entry_time'] = data['order_entry_time'].map(lambda x:pd.to_datetime(x))\n",
    "        \n",
    "        allorder = data\n",
    "        allorder['prc*qty'] = allorder['avg_prc']        \n",
    "        allorder['execution_time_last_ms'] = allorder['execution_time'].map(toMS)\n",
    "        allorder['order_entry_time_ms'] = allorder['order_entry_time'].map(toMS)\n",
    "        \n",
    "        allorder['q_cancel'] = allorder['q_new'] - allorder['q_exec']\n",
    "        allorder.set_index('orderid',inplace=True)\n",
    "        allorder = allorder.sort('order_entry_time')\n",
    "        return allorder\n",
    "    \n",
    "    def cleanData(self,data):\n",
    "        data['q_exec'].fillna(0,inplace=True)\n",
    "        data['execution_time'] = data['execution_time'].map(lambda x:pd.to_datetime(x))\n",
    "        data['cancel_entry_time'] = data['cancel_entry_time'].map(lambda x:pd.to_datetime(x))\n",
    "        data['order_entry_time'] = data['order_entry_time'].map(lambda x:pd.to_datetime(x))\n",
    "        data['prc*qty'] = data['q_exec']*data['prc_exec']\n",
    "\n",
    "        neworder = data.loc[data['order_type']=='NEW ORDER',:]\n",
    "        exeorder = data.loc[data['order_type']=='EXECUTION',:]\n",
    "        canorder = data.loc[data['order_type']=='CANCEL',:].copy()\n",
    "    \n",
    "        ############## Exclude those partial filled orders from cancel list\n",
    "        #partialfill = set(canorder['orderid']).intersection(set(exeorder['orderid']))\n",
    "        #canorder = canorder.loc[canorder['orderid'].isin(partialfill)==False,:]\n",
    "        #####################################################################\n",
    "   \n",
    "        allorder = neworder[['id','orderid','symbol','q_new','price','order_entry_time','date','time','side']].set_index('orderid')\n",
    "        gp = exeorder.groupby('orderid')\n",
    "        tmp = gp.agg({'q_exec':np.sum,'prc*qty':np.sum})\n",
    "        tmp['avg exe_prc'] = tmp['prc*qty']/tmp['q_exec']\n",
    "        del tmp['prc*qty']\n",
    "        allorder = allorder.join(tmp)\n",
    "    #allorder = allorder.join(gp['execute_time'].agg({'first_exe_time':np.min,'last_exe_time':np.max}))\n",
    "        allorder = allorder.join(gp['execution_time'].agg({'first_execution_time':np.min,'last_execution_time':np.max}))\n",
    "        allorder['execution_time_first_ms'] = allorder['first_execution_time'].map(toMS)\n",
    "        allorder['execution_time_last_ms'] = allorder['last_execution_time'].map(toMS)\n",
    "        allorder['order_entry_time_ms'] = allorder['order_entry_time'].map(toMS)\n",
    "    #gp = canorder.groupby('orderid')\n",
    "        allorder = allorder.join(canorder.set_index('orderid')[['cancel_entry_time','canc_time']])\n",
    "        allorder['q_exec'].fillna(0,inplace=True)\n",
    "        allorder['q_cancel'] = allorder['q_new'] - allorder['q_exec']\n",
    "        allorder = allorder.sort('order_entry_time')\n",
    "        return allorder\n",
    "    \n",
    "    def prepare(self,allorder):\n",
    "        ''' resort all the order according the the order entry time (canceled order) and exe time(filled order)\n",
    "            Calculate the time difference\n",
    "        '''\n",
    "        fillorder = allorder.loc[allorder['q_exec']>0,['date','price','side','last_execution_time','execution_time_last_ms','q_exec']]\n",
    "        fillorder['exec buy'] = fillorder['q_exec']\n",
    "        fillorder['exec sell'] = fillorder['q_exec']\n",
    "        fillorder.loc[fillorder['side']=='B','exec sell'] = 0\n",
    "        fillorder.loc[fillorder['side']!='B','exec buy'] = 0\n",
    "        fillorder = fillorder.rename(columns={'execution_time_last_ms':'microsecond','last_execution_time':'time'})\n",
    "\n",
    "    #canorder = allorder.loc[allorder['q_cancel']>0,['date','price','side','order_entry_time','order_entry_time_ms','q_cancel']]\n",
    "        canorder = allorder.loc[allorder['q_cancel']==allorder['q_new'],['date','price','side','order_entry_time','order_entry_time_ms','q_cancel']]\n",
    "    #partially filled order discarded\n",
    "    #import pdb;pdb.set_trace()\n",
    "        canorder['cancelled buy'] = canorder['q_cancel']\n",
    "        canorder['cancelled sell'] = canorder['q_cancel']\n",
    "        canorder.loc[canorder['side']=='B','cancelled sell'] = 0.0\n",
    "        canorder.loc[canorder['side']!='B','cancelled buy'] = 0.0\n",
    "        canorder = canorder.rename(columns={'order_entry_time_ms':'microsecond','order_entry_time':'time'})\n",
    "\n",
    "        fillorder['cancelled buy'] = 0\n",
    "        fillorder['cancelled sell'] = 0\n",
    "        canorder['exec buy'] = 0\n",
    "        canorder['exec sell'] = 0\n",
    "        del canorder['q_cancel']\n",
    "        del fillorder['q_exec']\n",
    "        data = fillorder.append(canorder)\n",
    "        data = data.sort(['date','microsecond'])\n",
    "        data = data.reset_index()\n",
    "        #import pdb;pdb.set_trace()\n",
    "        for dd in data['date'].unique():\n",
    "            data.loc[data['date']==dd,'inventory'] = data.loc[data['date']==dd,'exec buy']-data.loc[data['date']==dd,'exec sell']\n",
    "            data.loc[data['date']==dd,'inventory'] = data.loc[data['date']==dd,'inventory'].cumsum()\n",
    "            data.loc[data['date']==dd,'time diff']= data.loc[data['date']==dd,'microsecond'].diff()*1. \n",
    "        data['time diff'] = data['time diff'].fillna(24*3600*1000000)\n",
    "        return data\n",
    "    \n",
    "    def HMMPrep(self,df):\n",
    "        #import pdb;pdb.set_trace()\n",
    "        col = ['orderid','cancelled buy','exec sell','cancelled sell','exec buy','microsecond','price','side','time','date','inventory','time diff',\n",
    "         'ewav_back canc buy','ewav_back canc sell','ewav_back exec buy','ewav_back exec sell','ewav_back buy/sell','ewav_back sell/buy']\n",
    "        if 'IsSpoof' in df.columns:\n",
    "            col +=['IsSpoof']\n",
    "        df = df[col]\n",
    "        del df['ewav_back exec buy']\n",
    "        del df['ewav_back exec sell']\n",
    "        # clean the data for ewav_back canc buy/sell and sell/buy\n",
    "        # buy/sell will be just inverse of sell/buy, so we use one column buy/sell\n",
    "        df.loc[(df['ewav_back canc buy']<1e-5)&(df['ewav_back canc sell']<1e-5),'ewav_back buy/sell']=1\n",
    "        medianbs = df.loc[(df['ewav_back buy/sell']>0)&(df['ewav_back buy/sell']<np.inf),'ewav_back buy/sell'].median()\n",
    "        maxbs = df.loc[(df['ewav_back buy/sell']>0)&(df['ewav_back buy/sell']<np.inf),'ewav_back buy/sell'].max()\n",
    "        df.loc[df['ewav_back buy/sell']==np.inf,'ewav_back buy/sell'] = maxbs\n",
    "        df.loc[df['ewav_back buy/sell']==0,'ewav_back buy/sell'] = 1/maxbs\n",
    "        df.loc[:,'ewav_back buy/sell'] = df.loc[:,'ewav_back buy/sell'].map(np.log)\n",
    "        \n",
    "        ## Get the time difference, seems not contributing for now\n",
    "        df['TimeDiff_back'] = np.nan\n",
    "        df['TimeDiff_frwd'] = np.nan\n",
    "        df['TimeDiff_min'] = np.nan\n",
    "        #import pdb;pdb.set_trace()\n",
    "        \n",
    "        df = df.loc[(df['exec sell']>0)|(df['exec buy']>0),:].copy()\n",
    "        if len(df)==0:\n",
    "            return df\n",
    "        buy = df.loc[df['side']=='B',:].copy()\n",
    "        if len(buy)>0:\n",
    "            for dd in buy['date'].unique():\n",
    "            #import pdb;pdb.set_trace()\n",
    "                tmp = buy.loc[buy['date']==dd,:]\n",
    "                buy.loc[buy['date']==dd,'TimeDiff_back'] = buy.loc[buy['date']==dd,'microsecond'].diff(1).map(lambda x:np.abs(x))\n",
    "                buy.loc[buy['date']==dd,'TimeDiff_frwd'] = buy.loc[buy['date']==dd,'microsecond'].diff(-1).map(lambda x:np.abs(x))\n",
    "            #import pdb;pdb.set_trace()    \n",
    "            buy['TimeDiff_frwd'].fillna(buy['TimeDiff_frwd'].max(),inplace=True)    \n",
    "            buy['TimeDiff_back'].fillna(buy['TimeDiff_back'].max(),inplace=True)\n",
    "            buy['TimeDiff_min'] = buy.apply(lambda x:min(x['TimeDiff_back'],x['TimeDiff_frwd']),axis=1)\n",
    "\n",
    "        sell = df.loc[df['side']=='S',:].copy()\n",
    "        if len(sell)>0:\n",
    "            for dd in sell['date'].unique():\n",
    "                tmp = sell.loc[sell['date']==dd,:]\n",
    "                sell.loc[sell['date']==dd,'TimeDiff_back'] = sell.loc[sell['date']==dd,'microsecond'].diff(1).map(lambda x:np.abs(x))\n",
    "                sell.loc[sell['date']==dd,'TimeDiff_frwd'] = sell.loc[sell['date']==dd,'microsecond'].diff(-1).map(lambda x:np.abs(x))\n",
    "    \n",
    "            sell['TimeDiff_frwd'].fillna(sell['TimeDiff_frwd'].max(),inplace=True)\n",
    "            sell['TimeDiff_back'].fillna(sell['TimeDiff_back'].max(),inplace=True)\n",
    "            sell['TimeDiff_min'] = sell.apply(lambda x:min(x['TimeDiff_back'],x['TimeDiff_frwd']),axis=1)\n",
    "\n",
    "        newdf = buy.append(sell)\n",
    "        newdf['date'] = newdf['date'].map(lambda x:pd.to_datetime(x))\n",
    "        #newdf = newdf.sort(['date','microsecond'])\n",
    "        df = newdf.sort()\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "class RFModel:\n",
    "    def __init__(self,n_estimators,max_depth):\n",
    "        self.rf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n",
    "        self.label_map = {}\n",
    "        self.rev_map = {}\n",
    "        \n",
    "        #self.label_set = label_set\n",
    "        \n",
    "    def fit(self,x1,label1,x2,label2):\n",
    "        ''' we assume x1,x2 are numpy arrays (1-d)\n",
    "        '''\n",
    "        label = np.array([0]*len(x1)+[1]*len(x2))\n",
    "        self.label_map = {0:label1,1:label2}\n",
    "        self.rev_map ={label1:0,label2:1}\n",
    "        data = np.concatenate((x1,x2)).reshape((len(x1)+len(x2),1))\n",
    "        self.rf.fit(data,label)\n",
    "        if False:\n",
    "            self.showResult(x1,label1,x2,label2)\n",
    "    \n",
    "    def showResult(self,x1,label1,x2,label2):\n",
    "        #import pdb;pdb.set_trace()\n",
    "        plt.hist(np.array(x1),bins=100,alpha=0.5,normed=True)\n",
    "        plt.hist(np.array(x2),bins=100,alpha=0.5,normed=True)\n",
    "        tt = np.arange(-50,50,0.05)\n",
    "        tt = tt.reshape((len(tt),1))\n",
    "        proba = self.rf.predict_proba(tt)\n",
    "        plt.plot(tt,proba[:,0],color='b')\n",
    "        plt.plot(tt,proba[:,1],color='r')\n",
    "        plt.show()\n",
    "        \n",
    "    def score(self,x,label):\n",
    "        ''' give score in log prob for the class denoted by label\n",
    "        '''\n",
    "        proba = self.rf.predict_proba(np.array(x).reshape((len(x),1)))\n",
    "        return np.log(proba[:,self.rev_map[label]])\n",
    "    \n",
    "    def prob(self,x,label):\n",
    "        ''' give score in log prob for the class denoted by label\n",
    "        '''\n",
    "        proba = self.rf.predict_proba(np.array(x).reshape((len(x),1)))\n",
    "        return proba[:,self.rev_map[label]]\n",
    "    \n",
    "    \n",
    "class RFWrapper():\n",
    "    def __init__(self,rf,label):\n",
    "        self.rf = rf\n",
    "        self.label= label\n",
    "    def score(self,x):\n",
    "        return self.rf.score(x,self.label)\n",
    "    def prob(self,x):\n",
    "        return self.rf.prob(x,self.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HMM:\n",
    "    def __init__(self,nState,TDFeaSet,featureSet,useAllFea,useDPGMM=True):\n",
    "        '''\n",
    "        recommended value for featureSet=['ewav_back buy/sell']\n",
    "        '''\n",
    "        self.TDFeaSet = TDFeaSet\n",
    "        self.featureSet = featureSet\n",
    "        self.useDPGMM = useDPGMM\n",
    "        self.useAllFea = useAllFea\n",
    "        #self.df = data\n",
    "        self.nState = nState\n",
    "        self.tp = None\n",
    "        self.pi = None\n",
    "        self.TDmodel = []\n",
    "        self.RatioModel = []\n",
    "    \n",
    "    def train(self,df,show=False):\n",
    "        self.pi = np.array(df.groupby('state').size()*1.0/len(df))\n",
    "        \n",
    "        df['next state'] = df['state'].shift(-1)    \n",
    "\n",
    "        gp = df.groupby(['state','next state','date']).size()\n",
    "        aa = gp.sum(level=[0,1])\n",
    "        bb = gp.sum(level=0)*1.\n",
    "        self.tp = aa/bb\n",
    "\n",
    "        print '---- Transition prob:'\n",
    "        print self.tp\n",
    "        \n",
    "        self.RatioModel = []\n",
    "        \n",
    "        ### RF model for ratio #############\n",
    "        \n",
    "        ratio0 = df.loc[df['state']==0,self.featureSet]\n",
    "        ratio2 = df.loc[df['state']==2,self.featureSet]\n",
    "        rf_buy = RFModel(n_estimators=10,max_depth=2)\n",
    "        rf_buy.fit(ratio0,0,ratio2,2)\n",
    "        \n",
    "        ratio1 = df.loc[df['state']==1,self.featureSet]\n",
    "        ratio3 = df.loc[df['state']==3,self.featureSet]\n",
    "        rf_sell = RFModel(n_estimators=10,max_depth=2)\n",
    "        rf_sell.fit(ratio1,1,ratio3,3)\n",
    "        \n",
    "        self.RatioModel=[RFWrapper(rf_buy,0),RFWrapper(rf_sell,1),RFWrapper(rf_buy,2),RFWrapper(rf_sell,3)]            \n",
    "    \n",
    "    def stateProb(self,obs):\n",
    "        '''Give the estimate of the probablity of each state at each time instance\n",
    "        '''\n",
    "        rtlist = []\n",
    "    \n",
    "        nState = self.nState\n",
    "        RatioModel = self.RatioModel\n",
    "        \n",
    "        for rt in RatioModel:    \n",
    "            rtlist.append(list(rt.score(np.array(obs[self.featureSet])))) #low efficiency code\n",
    "        \n",
    "        rtprob = np.asmatrix(rtlist)\n",
    "\n",
    "        distrprob = rtprob\n",
    "        \n",
    "        logtp = np.log(self.tp)\n",
    "        logpi = np.log(self.pi)\n",
    "    \n",
    "        alpha = np.zeros((nState,len(obs)))\n",
    "        beta = np.zeros((nState,len(obs)))\n",
    "    \n",
    "        isbuy = obs['side'].map(lambda x:int(x=='B'))\n",
    "        issell = obs['side'].map(lambda x:int(x=='S'))\n",
    "        validState = np.asmatrix([isbuy,issell,isbuy,issell]) # 0 means not valid\n",
    "        dumb = -1e5 #used to fill for np.log(zero)\n",
    "    \n",
    "        alpha[:,0] = np.squeeze(np.asarray(distrprob[:,0])) + logpi\n",
    "        for ii in range(1,len(obs)):\n",
    "            for kk in range(nState):\n",
    "                if validState[kk,ii]==0:\n",
    "                    alpha[kk,ii] = dumb\n",
    "                else:\n",
    "                    tmp = alpha[:,ii-1] + logtp[:,kk]\n",
    "                    maxtmp = np.max(tmp)\n",
    "                    tmp = tmp - maxtmp\n",
    "                    alpha[kk,ii] = maxtmp + np.log(np.sum(np.exp(tmp))) + distrprob[kk,ii]\n",
    "        \n",
    "        for ii in range(len(obs)-2,-1,-1):\n",
    "            for kk in range(nState):\n",
    "                if validState[kk,ii] == 0:\n",
    "                    beta[kk,ii] = dumb\n",
    "                else:\n",
    "                    tmp = np.asarray(logtp[kk])+beta[:,ii+1]+np.squeeze(np.asarray(distrprob[:,ii+1]))\n",
    "                    maxtmp = np.max(tmp)\n",
    "                    tmp = tmp - maxtmp\n",
    "                    beta[kk,ii] = maxtmp + np.log(np.sum(np.exp(tmp)))\n",
    "            \n",
    "        gamma = alpha+beta # not exactly the gamma\n",
    "        maxgamma = np.max(gamma,0)\n",
    "        gamma = gamma - np.kron(np.reshape(maxgamma,(1,len(obs))),np.ones((nState,1)))\n",
    "        gamma = np.exp(gamma)\n",
    "        sumgamma = np.kron(np.sum(gamma,0),np.ones((nState,1)))\n",
    "        gamma = gamma/sumgamma   \n",
    "        return gamma\n",
    "    \n",
    "    def predict(self,df):\n",
    "        ''' needs more work,better return a dataframe\n",
    "        '''\n",
    "        #import pdb;pdb.set_trace()\n",
    "        data = df.copy()\n",
    "        prob = self.stateProb(data)\n",
    "        pred = np.argmax(prob,0)\n",
    "        pred_prob=np.max(prob,0)\n",
    "        data['pred'] = pred\n",
    "        data['pred_prob'] = pred_prob\n",
    "        data['predSpoofing'] = data['pred'].map(lambda x:x>1)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Transition prob:\n",
      "state  next state\n",
      "0      0.0           0.706235\n",
      "       1.0           0.161871\n",
      "       2.0           0.026379\n",
      "       3.0           0.105516\n",
      "1      0.0           0.217391\n",
      "       1.0           0.653673\n",
      "       2.0           0.076462\n",
      "       3.0           0.052474\n",
      "2      0.0           0.107143\n",
      "       1.0           0.202381\n",
      "       2.0           0.678571\n",
      "       3.0           0.011905\n",
      "3      0.0           0.190104\n",
      "       1.0           0.117188\n",
      "       2.0           0.018229\n",
      "       3.0           0.674479\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "traindf = pd.read_csv('traindf.csv')\n",
    "mm = HMM(nState=4,TDFeaSet=['TimeDiff_frwd','TimeDiff_back'],featureSet=['ewav_back buy/sell'],useAllFea=False,useDPGMM=True)\n",
    "mm.train(traindf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after processing:  14363\n",
      "----Data cleaning----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/qau/share/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:102: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "/qau/share/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:167: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Feature calculation----\n",
      "> <ipython-input-3-60a98d744258>(62)computeEWAVBackward()\n",
      "-> for ii in range(1,len(data)):\n",
      "(Pdb) data['time_diff']\n",
      "*** KeyError: 'time_diff'\n",
      "(Pdb) data['time diff']\n",
      "0        8.640000e+10\n",
      "1        0.000000e+00\n",
      "2        6.570000e+06\n",
      "3        0.000000e+00\n",
      "4        1.643440e+09\n",
      "5        2.361450e+08\n",
      "6        0.000000e+00\n",
      "7        3.518400e+07\n",
      "8        1.489155e+09\n",
      "9        0.000000e+00\n",
      "10       0.000000e+00\n",
      "11       0.000000e+00\n",
      "12       1.313800e+08\n",
      "13       4.250300e+07\n",
      "14       0.000000e+00\n",
      "15       1.363530e+08\n",
      "16       0.000000e+00\n",
      "17       4.425000e+06\n",
      "18       0.000000e+00\n",
      "19       9.000000e+03\n",
      "20       0.000000e+00\n",
      "21       1.412731e+09\n",
      "22       0.000000e+00\n",
      "23       1.000000e+03\n",
      "24       0.000000e+00\n",
      "25       9.000000e+03\n",
      "26       0.000000e+00\n",
      "27       3.000000e+03\n",
      "28       0.000000e+00\n",
      "29       9.166000e+07\n",
      "             ...     \n",
      "14333    7.000000e+03\n",
      "14334    0.000000e+00\n",
      "14335    9.000000e+03\n",
      "14336    0.000000e+00\n",
      "14337    2.480000e+06\n",
      "14338    0.000000e+00\n",
      "14339    8.000000e+03\n",
      "14340    0.000000e+00\n",
      "14341    1.175590e+08\n",
      "14342    0.000000e+00\n",
      "14343    1.000000e+04\n",
      "14344    5.000000e+03\n",
      "14345    8.640000e+10\n",
      "14346    0.000000e+00\n",
      "14347    7.000000e+03\n",
      "14348    0.000000e+00\n",
      "14349    8.640000e+10\n",
      "14350    0.000000e+00\n",
      "14351    9.000000e+03\n",
      "14352    0.000000e+00\n",
      "14353    9.000000e+03\n",
      "14354    0.000000e+00\n",
      "14355    1.471200e+07\n",
      "14356    0.000000e+00\n",
      "14357    1.000000e+04\n",
      "14358    0.000000e+00\n",
      "14359    9.000000e+03\n",
      "14360    0.000000e+00\n",
      "14361    8.640000e+10\n",
      "14362    0.000000e+00\n",
      "Name: time diff, dtype: float64\n",
      "(Pdb) data\n",
      "          orderid  cancelled buy  cancelled sell                     date  \\\n",
      "0      4605204951            0.0          1000.0  2013-01-02 00:00:00.000   \n",
      "1      4605204951            0.0          1000.0  2013-01-02 00:00:00.000   \n",
      "2      4605204952            0.0          1000.0  2013-01-02 00:00:00.000   \n",
      "3      4605204952            0.0          1000.0  2013-01-02 00:00:00.000   \n",
      "4      4605205325            0.0          1000.0  2013-01-02 00:00:00.000   \n",
      "5      4605205411            0.0          1000.0  2013-01-02 00:00:00.000   \n",
      "6      4605205411            0.0          1000.0  2013-01-02 00:00:00.000   \n",
      "7      4605205411            0.0             0.0  2013-01-02 00:00:00.000   \n",
      "8      4605206067            0.0          1515.0  2013-01-02 00:00:00.000   \n",
      "9      4605206068            0.0          1729.0  2013-01-02 00:00:00.000   \n",
      "10     4605206067            0.0          1515.0  2013-01-02 00:00:00.000   \n",
      "11     4605206068            0.0          1729.0  2013-01-02 00:00:00.000   \n",
      "12     4605205325            0.0             0.0  2013-01-02 00:00:00.000   \n",
      "13     4605206534            0.0          2244.0  2013-01-02 00:00:00.000   \n",
      "14     4605206534            0.0          2244.0  2013-01-02 00:00:00.000   \n",
      "15     4605206967            0.0           500.0  2013-01-02 00:00:00.000   \n",
      "16     4605206967            0.0           500.0  2013-01-02 00:00:00.000   \n",
      "17     4605206996            0.0           500.0  2013-01-02 00:00:00.000   \n",
      "18     4605206996            0.0           500.0  2013-01-02 00:00:00.000   \n",
      "19     4605206998            0.0           500.0  2013-01-02 00:00:00.000   \n",
      "20     4605206998            0.0           500.0  2013-01-02 00:00:00.000   \n",
      "21     4605209372            0.0          1244.0  2013-01-02 00:00:00.000   \n",
      "22     4605209372            0.0          1244.0  2013-01-02 00:00:00.000   \n",
      "23     4605209374            0.0          1000.0  2013-01-02 00:00:00.000   \n",
      "24     4605209374            0.0          1000.0  2013-01-02 00:00:00.000   \n",
      "25     4605209376            0.0          1244.0  2013-01-02 00:00:00.000   \n",
      "26     4605209376            0.0          1244.0  2013-01-02 00:00:00.000   \n",
      "27     4605209377            0.0          1000.0  2013-01-02 00:00:00.000   \n",
      "28     4605209377            0.0          1000.0  2013-01-02 00:00:00.000   \n",
      "29     4605209469            0.0          2244.0  2013-01-02 00:00:00.000   \n",
      "...           ...            ...             ...                      ...   \n",
      "14333  4641246599         1000.0             0.0  2013-09-09 00:00:00.000   \n",
      "14334  4641246599         1000.0             0.0  2013-09-09 00:00:00.000   \n",
      "14335  4641246601         1000.0             0.0  2013-09-09 00:00:00.000   \n",
      "14336  4641246601         1000.0             0.0  2013-09-09 00:00:00.000   \n",
      "14337  4641246604            0.0          1000.0  2013-09-09 00:00:00.000   \n",
      "14338  4641246604            0.0          1000.0  2013-09-09 00:00:00.000   \n",
      "14339  4641246615            0.0          1000.0  2013-09-09 00:00:00.000   \n",
      "14340  4641246615            0.0          1000.0  2013-09-09 00:00:00.000   \n",
      "14341  4641246977            0.0          1000.0  2013-09-09 00:00:00.000   \n",
      "14342  4641246977            0.0          1000.0  2013-09-09 00:00:00.000   \n",
      "14343  4641246980            0.0          1000.0  2013-09-09 00:00:00.000   \n",
      "14344  4641246980            0.0             0.0  2013-09-09 00:00:00.000   \n",
      "14345  4648291179          100.0             0.0  2013-10-23 00:00:00.000   \n",
      "14346  4648291179          100.0             0.0  2013-10-23 00:00:00.000   \n",
      "14347  4648291181          100.0             0.0  2013-10-23 00:00:00.000   \n",
      "14348  4648291181          100.0             0.0  2013-10-23 00:00:00.000   \n",
      "14349  4649139798        10000.0             0.0  2013-10-28 00:00:00.000   \n",
      "14350  4649139798        10000.0             0.0  2013-10-28 00:00:00.000   \n",
      "14351  4649139800        10000.0             0.0  2013-10-28 00:00:00.000   \n",
      "14352  4649139800        10000.0             0.0  2013-10-28 00:00:00.000   \n",
      "14353  4649139802        10000.0             0.0  2013-10-28 00:00:00.000   \n",
      "14354  4649139802        10000.0             0.0  2013-10-28 00:00:00.000   \n",
      "14355  4649139900         5000.0             0.0  2013-10-28 00:00:00.000   \n",
      "14356  4649139900         5000.0             0.0  2013-10-28 00:00:00.000   \n",
      "14357  4649139902         5000.0             0.0  2013-10-28 00:00:00.000   \n",
      "14358  4649139902         5000.0             0.0  2013-10-28 00:00:00.000   \n",
      "14359  4649139904         5000.0             0.0  2013-10-28 00:00:00.000   \n",
      "14360  4649139904         5000.0             0.0  2013-10-28 00:00:00.000   \n",
      "14361  4649392262            0.0          5000.0  2013-10-29 00:00:00.000   \n",
      "14362  4649392262            0.0          5000.0  2013-10-29 00:00:00.000   \n",
      "\n",
      "       exec buy  exec sell   microsecond  price side  \\\n",
      "0           0.0        0.0  2.525813e+10    NaN    S   \n",
      "1           0.0        0.0  2.525813e+10    NaN    S   \n",
      "2           0.0        0.0  2.526470e+10    NaN    S   \n",
      "3           0.0        0.0  2.526470e+10    NaN    S   \n",
      "4           0.0        0.0  2.690814e+10    NaN    S   \n",
      "5           0.0        0.0  2.714428e+10    NaN    S   \n",
      "6           0.0        0.0  2.714428e+10    NaN    S   \n",
      "7           0.0      271.0  2.717946e+10    NaN    S   \n",
      "8           0.0        0.0  2.866862e+10    NaN    S   \n",
      "9           0.0        0.0  2.866862e+10    NaN    S   \n",
      "10          0.0        0.0  2.866862e+10    NaN    S   \n",
      "11          0.0        0.0  2.866862e+10    NaN    S   \n",
      "12          0.0     1000.0  2.880000e+10    NaN    S   \n",
      "13          0.0        0.0  2.884250e+10    NaN    S   \n",
      "14          0.0        0.0  2.884250e+10    NaN    S   \n",
      "15          0.0        0.0  2.897886e+10    NaN    S   \n",
      "16          0.0        0.0  2.897886e+10    NaN    S   \n",
      "17          0.0        0.0  2.898328e+10    NaN    S   \n",
      "18          0.0        0.0  2.898328e+10    NaN    S   \n",
      "19          0.0        0.0  2.898329e+10    NaN    S   \n",
      "20          0.0        0.0  2.898329e+10    NaN    S   \n",
      "21          0.0        0.0  3.039602e+10    NaN    S   \n",
      "22          0.0        0.0  3.039602e+10    NaN    S   \n",
      "23          0.0        0.0  3.039602e+10    NaN    S   \n",
      "24          0.0        0.0  3.039602e+10    NaN    S   \n",
      "25          0.0        0.0  3.039603e+10    NaN    S   \n",
      "26          0.0        0.0  3.039603e+10    NaN    S   \n",
      "27          0.0        0.0  3.039603e+10    NaN    S   \n",
      "28          0.0        0.0  3.039603e+10    NaN    S   \n",
      "29          0.0        0.0  3.048769e+10    NaN    S   \n",
      "...         ...        ...           ...    ...  ...   \n",
      "14333       0.0        0.0  3.314971e+10    NaN    B   \n",
      "14334       0.0        0.0  3.314971e+10    NaN    B   \n",
      "14335       0.0        0.0  3.314972e+10    NaN    B   \n",
      "14336       0.0        0.0  3.314972e+10    NaN    B   \n",
      "14337       0.0        0.0  3.315220e+10    NaN    S   \n",
      "14338       0.0        0.0  3.315220e+10    NaN    S   \n",
      "14339       0.0        0.0  3.315220e+10    NaN    S   \n",
      "14340       0.0        0.0  3.315220e+10    NaN    S   \n",
      "14341       0.0        0.0  3.326976e+10    NaN    S   \n",
      "14342       0.0        0.0  3.326976e+10    NaN    S   \n",
      "14343       0.0        0.0  3.326977e+10    NaN    S   \n",
      "14344       0.0     1000.0  3.326978e+10    NaN    S   \n",
      "14345       0.0        0.0  5.396369e+10    NaN    B   \n",
      "14346       0.0        0.0  5.396369e+10    NaN    B   \n",
      "14347       0.0        0.0  5.396370e+10    NaN    B   \n",
      "14348       0.0        0.0  5.396370e+10    NaN    B   \n",
      "14349       0.0        0.0  5.736433e+10    NaN    B   \n",
      "14350       0.0        0.0  5.736433e+10    NaN    B   \n",
      "14351       0.0        0.0  5.736434e+10    NaN    B   \n",
      "14352       0.0        0.0  5.736434e+10    NaN    B   \n",
      "14353       0.0        0.0  5.736435e+10    NaN    B   \n",
      "14354       0.0        0.0  5.736435e+10    NaN    B   \n",
      "14355       0.0        0.0  5.737906e+10    NaN    B   \n",
      "14356       0.0        0.0  5.737906e+10    NaN    B   \n",
      "14357       0.0        0.0  5.737907e+10    NaN    B   \n",
      "14358       0.0        0.0  5.737907e+10    NaN    B   \n",
      "14359       0.0        0.0  5.737908e+10    NaN    B   \n",
      "14360       0.0        0.0  5.737908e+10    NaN    B   \n",
      "14361       0.0        0.0  5.740834e+10    NaN    S   \n",
      "14362       0.0        0.0  5.740834e+10    NaN    S   \n",
      "\n",
      "                             time  inventory     time diff  \\\n",
      "0      1900-01-01 07:00:58.126000        0.0  8.640000e+10   \n",
      "1      1900-01-01 07:00:58.126000        0.0  0.000000e+00   \n",
      "2      1900-01-01 07:01:04.696000        0.0  6.570000e+06   \n",
      "3      1900-01-01 07:01:04.696000        0.0  0.000000e+00   \n",
      "4      1900-01-01 07:28:28.136000        0.0  1.643440e+09   \n",
      "5      1900-01-01 07:32:24.281000        0.0  2.361450e+08   \n",
      "6      1900-01-01 07:32:24.281000        0.0  0.000000e+00   \n",
      "7                             NaN     -271.0  3.518400e+07   \n",
      "8      1900-01-01 07:57:48.620000     -271.0  1.489155e+09   \n",
      "9      1900-01-01 07:57:48.620000     -271.0  0.000000e+00   \n",
      "10     1900-01-01 07:57:48.620000     -271.0  0.000000e+00   \n",
      "11     1900-01-01 07:57:48.620000     -271.0  0.000000e+00   \n",
      "12                            NaN    -1271.0  1.313800e+08   \n",
      "13     1900-01-01 08:00:42.503000    -1271.0  4.250300e+07   \n",
      "14     1900-01-01 08:00:42.503000    -1271.0  0.000000e+00   \n",
      "15     1900-01-01 08:02:58.856000    -1271.0  1.363530e+08   \n",
      "16     1900-01-01 08:02:58.856000    -1271.0  0.000000e+00   \n",
      "17     1900-01-01 08:03:03.281000    -1271.0  4.425000e+06   \n",
      "18     1900-01-01 08:03:03.281000    -1271.0  0.000000e+00   \n",
      "19     1900-01-01 08:03:03.290000    -1271.0  9.000000e+03   \n",
      "20     1900-01-01 08:03:03.290000    -1271.0  0.000000e+00   \n",
      "21     1900-01-01 08:26:36.021000    -1271.0  1.412731e+09   \n",
      "22     1900-01-01 08:26:36.021000    -1271.0  0.000000e+00   \n",
      "23     1900-01-01 08:26:36.022000    -1271.0  1.000000e+03   \n",
      "24     1900-01-01 08:26:36.022000    -1271.0  0.000000e+00   \n",
      "25     1900-01-01 08:26:36.031000    -1271.0  9.000000e+03   \n",
      "26     1900-01-01 08:26:36.031000    -1271.0  0.000000e+00   \n",
      "27     1900-01-01 08:26:36.034000    -1271.0  3.000000e+03   \n",
      "28     1900-01-01 08:26:36.034000    -1271.0  0.000000e+00   \n",
      "29     1900-01-01 08:28:07.694000    -1271.0  9.166000e+07   \n",
      "...                           ...        ...           ...   \n",
      "14333  1900-01-01 09:12:29.708000     1000.0  7.000000e+03   \n",
      "14334  1900-01-01 09:12:29.708000     1000.0  0.000000e+00   \n",
      "14335  1900-01-01 09:12:29.717000     1000.0  9.000000e+03   \n",
      "14336  1900-01-01 09:12:29.717000     1000.0  0.000000e+00   \n",
      "14337  1900-01-01 09:12:32.197000     1000.0  2.480000e+06   \n",
      "14338  1900-01-01 09:12:32.197000     1000.0  0.000000e+00   \n",
      "14339  1900-01-01 09:12:32.205000     1000.0  8.000000e+03   \n",
      "14340  1900-01-01 09:12:32.205000     1000.0  0.000000e+00   \n",
      "14341  1900-01-01 09:14:29.764000     1000.0  1.175590e+08   \n",
      "14342  1900-01-01 09:14:29.764000     1000.0  0.000000e+00   \n",
      "14343  1900-01-01 09:14:29.774000     1000.0  1.000000e+04   \n",
      "14344                         NaN        0.0  5.000000e+03   \n",
      "14345  1900-01-01 14:59:23.689000        0.0  8.640000e+10   \n",
      "14346  1900-01-01 14:59:23.689000        0.0  0.000000e+00   \n",
      "14347  1900-01-01 14:59:23.696000        0.0  7.000000e+03   \n",
      "14348  1900-01-01 14:59:23.696000        0.0  0.000000e+00   \n",
      "14349  1900-01-01 15:56:04.333000        0.0  8.640000e+10   \n",
      "14350  1900-01-01 15:56:04.333000        0.0  0.000000e+00   \n",
      "14351  1900-01-01 15:56:04.342000        0.0  9.000000e+03   \n",
      "14352  1900-01-01 15:56:04.342000        0.0  0.000000e+00   \n",
      "14353  1900-01-01 15:56:04.351000        0.0  9.000000e+03   \n",
      "14354  1900-01-01 15:56:04.351000        0.0  0.000000e+00   \n",
      "14355  1900-01-01 15:56:19.063000        0.0  1.471200e+07   \n",
      "14356  1900-01-01 15:56:19.063000        0.0  0.000000e+00   \n",
      "14357  1900-01-01 15:56:19.073000        0.0  1.000000e+04   \n",
      "14358  1900-01-01 15:56:19.073000        0.0  0.000000e+00   \n",
      "14359  1900-01-01 15:56:19.082000        0.0  9.000000e+03   \n",
      "14360  1900-01-01 15:56:19.082000        0.0  0.000000e+00   \n",
      "14361  1900-01-01 15:56:48.339000        0.0  8.640000e+10   \n",
      "14362  1900-01-01 15:56:48.339000        0.0  0.000000e+00   \n",
      "\n",
      "       ewav_back canc buy  ewav_back canc sell  ewav_back exec buy  \\\n",
      "0            2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "1            2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "2            2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "3            2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "4            2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "5            2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "6            2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "7            2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "8            2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "9            2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "10           2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "11           2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "12           2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "13           2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "14           2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "15           2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "16           2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "17           2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "18           2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "19           2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "20           2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "21           2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "22           2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "23           2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "24           2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "25           2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "26           2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "27           2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "28           2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "29           2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "...                   ...                  ...                 ...   \n",
      "14333        2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "14334        2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "14335        2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "14336        2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "14337        2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "14338        2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "14339        2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "14340        2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "14341        2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "14342        2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "14343        2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "14344        2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "14345        2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "14346        2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "14347        2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "14348        2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "14349        2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "14350        2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "14351        2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "14352        2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "14353        2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "14354        2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "14355        2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "14356        2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "14357        2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "14358        2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "14359        2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "14360        2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "14361        2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "14362        2.220446e-16         2.220446e-16        2.220446e-16   \n",
      "\n",
      "       ewav_back exec sell  \n",
      "0             2.220446e-16  \n",
      "1             2.220446e-16  \n",
      "2             2.220446e-16  \n",
      "3             2.220446e-16  \n",
      "4             2.220446e-16  \n",
      "5             2.220446e-16  \n",
      "6             2.220446e-16  \n",
      "7             2.220446e-16  \n",
      "8             2.220446e-16  \n",
      "9             2.220446e-16  \n",
      "10            2.220446e-16  \n",
      "11            2.220446e-16  \n",
      "12            2.220446e-16  \n",
      "13            2.220446e-16  \n",
      "14            2.220446e-16  \n",
      "15            2.220446e-16  \n",
      "16            2.220446e-16  \n",
      "17            2.220446e-16  \n",
      "18            2.220446e-16  \n",
      "19            2.220446e-16  \n",
      "20            2.220446e-16  \n",
      "21            2.220446e-16  \n",
      "22            2.220446e-16  \n",
      "23            2.220446e-16  \n",
      "24            2.220446e-16  \n",
      "25            2.220446e-16  \n",
      "26            2.220446e-16  \n",
      "27            2.220446e-16  \n",
      "28            2.220446e-16  \n",
      "29            2.220446e-16  \n",
      "...                    ...  \n",
      "14333         2.220446e-16  \n",
      "14334         2.220446e-16  \n",
      "14335         2.220446e-16  \n",
      "14336         2.220446e-16  \n",
      "14337         2.220446e-16  \n",
      "14338         2.220446e-16  \n",
      "14339         2.220446e-16  \n",
      "14340         2.220446e-16  \n",
      "14341         2.220446e-16  \n",
      "14342         2.220446e-16  \n",
      "14343         2.220446e-16  \n",
      "14344         2.220446e-16  \n",
      "14345         2.220446e-16  \n",
      "14346         2.220446e-16  \n",
      "14347         2.220446e-16  \n",
      "14348         2.220446e-16  \n",
      "14349         2.220446e-16  \n",
      "14350         2.220446e-16  \n",
      "14351         2.220446e-16  \n",
      "14352         2.220446e-16  \n",
      "14353         2.220446e-16  \n",
      "14354         2.220446e-16  \n",
      "14355         2.220446e-16  \n",
      "14356         2.220446e-16  \n",
      "14357         2.220446e-16  \n",
      "14358         2.220446e-16  \n",
      "14359         2.220446e-16  \n",
      "14360         2.220446e-16  \n",
      "14361         2.220446e-16  \n",
      "14362         2.220446e-16  \n",
      "\n",
      "[14363 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "dp = DataPrep(True)\n",
    "res = pd.DataFrame()\n",
    "total_spoof = 0\n",
    "total_trades = 0\n",
    "\n",
    "#for sym in df['symbol'].unique():\n",
    "syms = df['symbol'].unique()\n",
    "sym = syms[0]\n",
    "data = df[df['symbol']==sym].copy()\n",
    "data = process_dera(data)\n",
    "print 'after processing: ',len(data)\n",
    "xx,hmmdata = dp.processData(data,verbose=1)\n",
    "print len(hmmdata)\n",
    "if len(hmmdata)>=3:\n",
    "    tmp = mm.predict(hmmdata)\n",
    "    cur_spoof = len(tmp[tmp['predSpoofing']])\n",
    "    total_spoof += cur_spoof\n",
    "    res = res.append(tmp)\n",
    "    total_trades += len(hmmdata)\n",
    "    print 'ID={}, number of spoofing trade = {}, total trades = {}'.format(sym,cur_spoof,len(hmmdata))\n",
    "        \n",
    "print 'total finding ={}'.format(total_spoof)\n",
    "print 'total trades = {}'.format(total_trades)\n",
    "res.to_csv('dera.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('OrderSummary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_dera(df):\n",
    "    df = df.rename(columns={'order_shares':'q_new','exec_shares':'q_exec','order_time':'order_entry_time','exec_last_time':'execution_time','cxl_time':'cancel_entry_time'})\n",
    "    df['q_cancel'] = 0.0\n",
    "    no = df.copy()\n",
    "    no['order_type'] = 'NEW ORDER'\n",
    "    no['q_exec'] = 0.0\n",
    "    eo = df[df['fill_rate']>0].copy()\n",
    "    eo['order_type'] = 'EXECUTION'\n",
    "    co = df[df['fill_rate']!=1].copy()\n",
    "    co['order_type'] = 'CANCEL'\n",
    "    co['q_cancel'] = co['q_new'] * (1 - co['fill_rate'])\n",
    "    co['q_exec'] = 0.0\n",
    "    df = pd.concat([no,eo,co])\n",
    "    df = df.sort_values(['orderid','order_type'],0,[1,0])\n",
    "    df['avg_prc'] = 0.0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "syms = df['symbol'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = df[df['symbol']==syms[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6852"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv('sam')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
