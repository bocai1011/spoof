{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn import mixture\n",
    "from sklearn import metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepareTrainSet():    \n",
    "    df = pd.read_csv('labeled_sina_new.csv')\n",
    "    df = df[['orderid','IsSpoof','cancelled buy','exec sell','cancelled sell','exec buy','microsecond','price','side','time','date','inventory','time diff',\n",
    "         'ewav_back canc buy','ewav_back canc sell','ewav_back exec buy','ewav_back exec sell','ewav_back buy/sell','ewav_back sell/buy']]\n",
    "    del df['ewav_back exec buy']\n",
    "    del df['ewav_back exec sell']\n",
    "    # clean the data for ewav_back canc buy/sell and sell/buy\n",
    "    # buy/sell will be just inverse of sell/buy, so we use one column buy/sell\n",
    "    df.loc[(df['ewav_back canc buy']==0)&(df['ewav_back canc sell']==0),'ewav_back buy/sell']=1\n",
    "    medianbs = df.loc[(df['ewav_back buy/sell']>0)&(df['ewav_back buy/sell']<np.inf),'ewav_back buy/sell'].median()\n",
    "    maxbs = df.loc[(df['ewav_back buy/sell']>0)&(df['ewav_back buy/sell']<np.inf),'ewav_back buy/sell'].max()\n",
    "    df.loc[df['ewav_back buy/sell']==np.inf,'ewav_back buy/sell'] = maxbs\n",
    "    df.loc[df['ewav_back buy/sell']==0,'ewav_back buy/sell'] = 1/maxbs\n",
    "    df['ewav_back buy/sell'] = df['ewav_back buy/sell'].map(np.log)\n",
    "    # To get the time difference between current trade and its nearest trade at the same side\n",
    "    df['TimeDiff_back'] = np.nan\n",
    "    df['TimeDiff_frwd'] = np.nan\n",
    "    df['TimeDiff_min'] = np.nan\n",
    "    df = df.loc[(df['exec sell']>0)|(df['exec buy']>0),:].copy()\n",
    "\n",
    "    buy = df.loc[df['side']=='B',:].copy()\n",
    "    for dd in buy['date'].unique():\n",
    "        #import pdb;pdb.set_trace()\n",
    "        tmp = buy.loc[buy['date']==dd,:]\n",
    "        buy.loc[buy['date']==dd,'TimeDiff_back'] = buy.loc[buy['date']==dd,'microsecond'].diff(1).map(lambda x:np.abs(x))\n",
    "        buy.loc[buy['date']==dd,'TimeDiff_frwd'] = buy.loc[buy['date']==dd,'microsecond'].diff(-1).map(lambda x:np.abs(x))\n",
    "    #import pdb;pdb.set_trace()    \n",
    "    buy['TimeDiff_frwd'] = buy['TimeDiff_frwd'].fillna(buy['TimeDiff_frwd'].max())    \n",
    "    buy['TimeDiff_back'] = buy['TimeDiff_back'].fillna(buy['TimeDiff_back'].max())\n",
    "    buy['TimeDiff_min'] = buy.apply(lambda x:min(x['TimeDiff_back'],x['TimeDiff_frwd']),axis=1)\n",
    "\n",
    "    sell = df.loc[df['side']=='S',:].copy()\n",
    "    for dd in sell['date'].unique():\n",
    "        tmp = sell.loc[sell['date']==dd,:]\n",
    "        sell.loc[sell['date']==dd,'TimeDiff_back'] = sell.loc[sell['date']==dd,'microsecond'].diff(1).map(lambda x:np.abs(x))\n",
    "        sell.loc[sell['date']==dd,'TimeDiff_frwd'] = sell.loc[sell['date']==dd,'microsecond'].diff(-1).map(lambda x:np.abs(x))\n",
    "    \n",
    "    sell['TimeDiff_frwd'] = sell['TimeDiff_frwd'].fillna(sell['TimeDiff_frwd'].max())\n",
    "    sell['TimeDiff_back'] = sell['TimeDiff_back'].fillna(sell['TimeDiff_back'].max())\n",
    "    sell['TimeDiff_min'] = sell.apply(lambda x:min(x['TimeDiff_back'],x['TimeDiff_frwd']),axis=1)\n",
    "\n",
    "    newdf = buy.append(sell)\n",
    "    newdf['date'] = newdf['date'].map(lambda x:pd.to_datetime(x))\n",
    "    #newdf = newdf.sort(['date','microsecond'])\n",
    "    df = newdf.sort()\n",
    "    #Define states\n",
    "    s1 = {'side':'B','IsSpoof':False}\n",
    "    s2 = {'side':'S','IsSpoof':False}\n",
    "    s3 = {'side':'B','IsSpoof':True}\n",
    "    s4 = {'side':'S','IsSpoof':True}\n",
    "\n",
    "    df['state']=0\n",
    "    df.loc[(df['side']=='B')&(df['IsSpoof']==False),'state'] = 0\n",
    "    df.loc[(df['side']=='S')&(df['IsSpoof']==False),'state'] = 1\n",
    "    df.loc[(df['side']=='B')&(df['IsSpoof']==True),'state'] = 2\n",
    "    df.loc[(df['side']=='S')&(df['IsSpoof']==True),'state'] = 3\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def toMS(x):\n",
    "    return ((x.hour*60+x.minute)*60+x.second)*1000000+x.microsecond\n",
    "    \n",
    "    \n",
    "class DataPrep:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def processData(self,filename):\n",
    "        data = pd.read_csv(filename)\n",
    "        print '----Data cleaning----'\n",
    "        \n",
    "        allorder = self.cleanData(data)\n",
    "        data = self.prepare(allorder)\n",
    "        \n",
    "        print '---- Feature calculation----'\n",
    "        #data = self.computeEWAVForward(data)\n",
    "        allorder = self.computeEWAVBackward(data)\n",
    "        #data = self.computeSEV(data)\n",
    "        \n",
    "        print '----- Prepare for HMM------'\n",
    "        data = self.HMMPrep(allorder.copy())\n",
    "        return allorder,data\n",
    "    \n",
    "    def computeEWAVBackward(self,data):\n",
    "        if len(data)<2:\n",
    "            raise ValueError('data too short')\n",
    "        T=np.median(data['time diff'])*2\n",
    "        data['ewav_back canc buy']=0\n",
    "        data['ewav_back canc sell']=0\n",
    "        data['ewav_back exec buy']=0\n",
    "        data['ewav_back exec sell']=0\n",
    "    \n",
    "        for ii in range(1,len(data)):\n",
    "            data.loc[ii,'ewav_back canc buy'] = data.loc[ii,'cancelled buy']+data.loc[ii-1,'ewav_back canc buy']*math.exp(-data.ix[ii]['time diff']/T)\n",
    "            data.loc[ii,'ewav_back canc sell'] = data.loc[ii,'cancelled sell']+data.loc[ii-1,'ewav_back canc sell']*math.exp(-data.ix[ii]['time diff']/T)\n",
    "            data.loc[ii,'ewav_back exec buy'] = data.loc[ii,'exec buy']+data.loc[ii-1,'ewav_back exec buy']*math.exp(-data.ix[ii]['time diff']/T)\n",
    "            data.loc[ii,'ewav_back exec sell'] = data.loc[ii,'exec sell']+data.loc[ii-1,'ewav_back exec sell']*math.exp(-data.ix[ii]['time diff']/T)\n",
    "        data['ewav_back buy/sell'] = 0\n",
    "        data.loc[data['ewav_back canc sell']==0,'ewav_back buy/sell']= np.inf\n",
    "        data.loc[data['ewav_back canc sell']!=0,'ewav_back buy/sell'] = data.loc[data['ewav_back canc sell']!=0,'ewav_back canc buy']/data.loc[data['ewav_back canc sell']!=0,'ewav_back canc sell']\n",
    "    \n",
    "        data['ewav_back sell/buy'] = 0\n",
    "        data.loc[data['ewav_back canc buy']==0,'ewav_back sell/buy'] = np.inf\n",
    "        data.loc[data['ewav_back canc buy']!=0,'ewav_back sell/buy'] = data.loc[data['ewav_back canc buy']!=0,'ewav_back canc sell']/data.loc[data['ewav_back canc buy']!=0,'ewav_back canc buy']\n",
    "    \n",
    "        data['ewav_back buy exec/total'] = 0\n",
    "        data['ewav_back buy exec+canc'] = data['ewav_back exec buy'] + data['ewav_back canc buy']\n",
    "        data.loc[data['ewav_back buy exec+canc']==0,'ewav_back buy exec/total']= 1\n",
    "        data.loc[data['ewav_back buy exec+canc']!=0,'ewav_back buy exec/total'] = data.loc[data['ewav_back buy exec+canc']!=0,'ewav_back exec buy']/data.loc[data['ewav_back buy exec+canc']!=0,'ewav_back buy exec+canc']\n",
    "    \n",
    "        data['ewav_back sell exec/total'] = 0\n",
    "        data['ewav_back sell exec+canc'] = data['ewav_back exec sell'] + data['ewav_back canc sell']\n",
    "        data.loc[data['ewav_back sell exec+canc']==0,'ewav_back sell exec/total'] = 1\n",
    "        data.loc[data['ewav_back sell exec+canc']!=0,'ewav_back sell exec/total'] = data.loc[data['ewav_back sell exec+canc']!=0,'ewav_back exec sell']/data.loc[data['ewav_back sell exec+canc']!=0,'ewav_back sell exec+canc']\n",
    "    \n",
    "        return data\n",
    "    def computeEWAVForward(self,data):\n",
    "        if len(data)<2:\n",
    "            raise ValueError('data too short')\n",
    "        T=np.median(data['time diff'])*2\n",
    "        data['ewav_for canc buy']=0\n",
    "        data['ewav_for canc sell']=0\n",
    "        data['ewav_for exec buy']=0\n",
    "        data['ewav_for exec sell']=0\n",
    "    \n",
    "        for ii in range(len(data)-2,-1,-1):\n",
    "            data.loc[ii,'ewav_for canc buy'] = data.loc[ii,'cancelled buy']+data.loc[ii+1,'ewav_for canc buy']*math.exp(-data.ix[ii+1]['time diff']/T)\n",
    "            data.loc[ii,'ewav_for canc sell'] = data.loc[ii,'cancelled sell']+data.loc[ii+1,'ewav_for canc sell']*math.exp(-data.ix[ii+1]['time diff']/T)\n",
    "            data.loc[ii,'ewav_for exec buy'] = data.loc[ii,'exec buy']+data.loc[ii+1,'ewav_for exec buy']*math.exp(-data.ix[ii+1]['time diff']/T)\n",
    "            data.loc[ii,'ewav_for exec sell'] = data.loc[ii,'exec sell']+data.loc[ii+1,'ewav_for exec sell']*math.exp(-data.ix[ii+1]['time diff']/T)\n",
    "        data['ewav_for buy/sell'] = 0\n",
    "        data.loc[data['ewav_for canc sell']==0,'ewav_for buy/sell']= np.inf\n",
    "        data.loc[data['ewav_for canc sell']!=0,'ewav_for buy/sell'] = data.loc[data['ewav_for canc sell']!=0,'ewav_for canc buy']/data.loc[data['ewav_for canc sell']!=0,'ewav_for canc sell']\n",
    "    \n",
    "        data['ewav_for sell/buy'] = 0\n",
    "        data.loc[data['ewav_for canc buy']==0,'ewav_for sell/buy'] = np.inf\n",
    "        data.loc[data['ewav_for canc buy']!=0,'ewav_for sell/buy'] = data.loc[data['ewav_for canc buy']!=0,'ewav_for canc sell']/data.loc[data['ewav_for canc buy']!=0,'ewav_for canc buy']\n",
    "    \n",
    "        data['ewav_for buy exec/total'] = 0\n",
    "        data['ewav_for buy exec+canc'] = data['ewav_for exec buy'] + data['ewav_for canc buy']\n",
    "        data.loc[data['ewav_for buy exec+canc']==0,'ewav_for buy exec/total']= 1\n",
    "        data.loc[data['ewav_for buy exec+canc']!=0,'ewav_for buy exec/total'] = data.loc[data['ewav_for buy exec+canc']!=0,'ewav_for exec buy']/data.loc[data['ewav_for buy exec+canc']!=0,'ewav_for buy exec+canc']\n",
    "    \n",
    "        data['ewav_for sell exec/total'] = 0\n",
    "        data['ewav_for sell exec+canc'] = data['ewav_for exec sell'] + data['ewav_for canc sell']\n",
    "        data.loc[data['ewav_for sell exec+canc']==0,'ewav_for sell exec/total'] = 1\n",
    "        data.loc[data['ewav_for sell exec+canc']!=0,'ewav_for sell exec/total'] = data.loc[data['ewav_for sell exec+canc']!=0,'ewav_for exec sell']/data.loc[data['ewav_for sell exec+canc']!=0,'ewav_for sell exec+canc']\n",
    "    \n",
    "        return data\n",
    "    \n",
    "    def computeSEV(self,data):\n",
    "        data['sev buy']=0\n",
    "        data['sev sell']=0\n",
    "    \n",
    "        winsize = 4*np.median(data['time diff'])\n",
    "        top=len(data)-1\n",
    "        tail = top\n",
    "        while(top>=0):\n",
    "            while tail>=top:\n",
    "                if data.loc[tail,'microsecond']-data.loc[top,'microsecond'] <=winsize:\n",
    "                    break\n",
    "                tail-=1\n",
    "            tmpbuy = 0.\n",
    "            tmpsell = 0.\n",
    "            for ii in range(top,tail+1):\n",
    "                tmpbuy += data.loc[ii,'exec buy']\n",
    "                tmpsell += data.loc[ii,'exec sell']\n",
    "            data.loc[top,'sev buy']=tmpbuy\n",
    "            data.loc[top,'sev sell']=tmpsell\n",
    "            top -= 1\n",
    "        data['sev net buy'] = data['sev buy'] - data['sev sell']\n",
    "        data.loc[data['sev buy']==0,'sev sell/buy'] = np.inf\n",
    "        data.loc[data['sev buy']!=0,'sev sell/buy'] = data.loc[data['sev buy']!=0,'sev sell']/data.loc[data['sev buy']!=0,'sev buy']*1.\n",
    "        data.loc[data['sev sell']==0,'sev buy/sell'] = np.inf\n",
    "        data.loc[data['sev sell']!=0,'sev buy/sell'] = data.loc[data['sev sell']!=0,'sev buy']/data.loc[data['sev sell']!=0,'sev sell']*1.\n",
    "        return data  \n",
    "    \n",
    "    def cleanData(self,data):\n",
    "        \n",
    "        data['execution_time'] = data['execution_time'].map(lambda x:pd.to_datetime(x))\n",
    "        data['cancel_entry_time'] = data['cancel_entry_time'].map(lambda x:pd.to_datetime(x))\n",
    "        data['order_entry_time'] = data['order_entry_time'].map(lambda x:pd.to_datetime(x))\n",
    "        data['prc*qty'] = data['q_exec']*data['prc_exec']\n",
    "\n",
    "        neworder = data.loc[data['order_type']=='NEW ORDER',:]\n",
    "        exeorder = data.loc[data['order_type']=='EXECUTION',:]\n",
    "        canorder = data.loc[data['order_type']=='CANCEL',:].copy()\n",
    "    \n",
    "        ############## Exclude those partial filled orders from cancel list\n",
    "        #partialfill = set(canorder['orderid']).intersection(set(exeorder['orderid']))\n",
    "        #canorder = canorder.loc[canorder['orderid'].isin(partialfill)==False,:]\n",
    "        #####################################################################\n",
    "   \n",
    "        allorder = neworder[['id','orderid','symbol','q_new','price','order_entry_time','date','time','side']].set_index('orderid')\n",
    "        gp = exeorder.groupby('orderid')\n",
    "        tmp = gp.agg({'q_exec':np.sum,'prc*qty':np.sum})\n",
    "        tmp['avg exe_prc'] = tmp['prc*qty']/tmp['q_exec']\n",
    "        del tmp['prc*qty']\n",
    "        allorder = allorder.join(tmp)\n",
    "    #allorder = allorder.join(gp['execute_time'].agg({'first_exe_time':np.min,'last_exe_time':np.max}))\n",
    "        allorder = allorder.join(gp['execution_time'].agg({'first_execution_time':np.min,'last_execution_time':np.max}))\n",
    "        allorder['execution_time_first_ms'] = allorder['first_execution_time'].map(toMS)\n",
    "        allorder['execution_time_last_ms'] = allorder['last_execution_time'].map(toMS)\n",
    "        allorder['order_entry_time_ms'] = allorder['order_entry_time'].map(toMS)\n",
    "    #gp = canorder.groupby('orderid')\n",
    "        allorder = allorder.join(canorder.set_index('orderid')[['cancel_entry_time','canc_time']])\n",
    "        allorder['q_exec'].fillna(0,inplace=True)\n",
    "        allorder['q_cancel'] = allorder['q_new'] - allorder['q_exec']\n",
    "        allorder = allorder.sort('order_entry_time')\n",
    "        return allorder\n",
    "    \n",
    "    def prepare(self,allorder):\n",
    "    #import pdb;pdb.set_trace()\n",
    "        fillorder = allorder.loc[allorder['q_exec']>0,['date','price','side','last_execution_time','execution_time_last_ms','q_exec']]\n",
    "        fillorder['exec buy'] = fillorder['q_exec']\n",
    "        fillorder['exec sell'] = fillorder['q_exec']\n",
    "        fillorder.loc[fillorder['side']=='B','exec sell'] = 0\n",
    "        fillorder.loc[fillorder['side']!='B','exec buy'] = 0\n",
    "        fillorder = fillorder.rename(columns={'execution_time_last_ms':'microsecond','last_execution_time':'time'})\n",
    "\n",
    "    #canorder = allorder.loc[allorder['q_cancel']>0,['date','price','side','order_entry_time','order_entry_time_ms','q_cancel']]\n",
    "        canorder = allorder.loc[allorder['q_cancel']==allorder['q_new'],['date','price','side','order_entry_time','order_entry_time_ms','q_cancel']]\n",
    "    #partially filled order discarded\n",
    "    #import pdb;pdb.set_trace()\n",
    "        canorder['cancelled buy'] = canorder['q_cancel']\n",
    "        canorder['cancelled sell'] = canorder['q_cancel']\n",
    "        canorder.loc[canorder['side']=='B','cancelled sell'] = 0.0\n",
    "        canorder.loc[canorder['side']!='B','cancelled buy'] = 0.0\n",
    "        canorder = canorder.rename(columns={'order_entry_time_ms':'microsecond','order_entry_time':'time'})\n",
    "\n",
    "        fillorder['cancelled buy'] = 0\n",
    "        fillorder['cancelled sell'] = 0\n",
    "        canorder['exec buy'] = 0\n",
    "        canorder['exec sell'] = 0\n",
    "        del canorder['q_cancel']\n",
    "        del fillorder['q_exec']\n",
    "        data = fillorder.append(canorder)\n",
    "        data = data.sort('microsecond')\n",
    "        data = data.reset_index()\n",
    "        data['inventory'] = data['exec buy']-data['exec sell']\n",
    "        data['inventory'] = data['inventory'].cumsum()\n",
    "        data['time diff']= data['microsecond'].diff()*1.   \n",
    "        return data\n",
    "    \n",
    "    def HMMPrep(self,df):\n",
    "        col = ['orderid','cancelled buy','exec sell','cancelled sell','exec buy','microsecond','price','side','time','date','inventory','time diff',\n",
    "         'ewav_back canc buy','ewav_back canc sell','ewav_back exec buy','ewav_back exec sell','ewav_back buy/sell','ewav_back sell/buy']\n",
    "        if 'IsSpoof' in df.columns:\n",
    "            col +=['IsSpoof']\n",
    "        df = df[col]\n",
    "        del df['ewav_back exec buy']\n",
    "        del df['ewav_back exec sell']\n",
    "        # clean the data for ewav_back canc buy/sell and sell/buy\n",
    "        # buy/sell will be just inverse of sell/buy, so we use one column buy/sell\n",
    "        df.loc[(df['ewav_back canc buy']==0)&(df['ewav_back canc sell']==0),'ewav_back buy/sell']=1\n",
    "        medianbs = df.loc[(df['ewav_back buy/sell']>0)&(df['ewav_back buy/sell']<np.inf),'ewav_back buy/sell'].median()\n",
    "        maxbs = df.loc[(df['ewav_back buy/sell']>0)&(df['ewav_back buy/sell']<np.inf),'ewav_back buy/sell'].max()\n",
    "        df.loc[df['ewav_back buy/sell']==np.inf,'ewav_back buy/sell'] = maxbs\n",
    "        df.loc[df['ewav_back buy/sell']==0,'ewav_back buy/sell'] = 1/maxbs\n",
    "        df['ewav_back buy/sell'] = df['ewav_back buy/sell'].map(np.log)\n",
    "        \n",
    "        ## Get the time difference, seems not contributing for now\n",
    "        df['TimeDiff_back'] = np.nan\n",
    "        df['TimeDiff_frwd'] = np.nan\n",
    "        df['TimeDiff_min'] = np.nan\n",
    "        df = df.loc[(df['exec sell']>0)|(df['exec buy']>0),:].copy()\n",
    "\n",
    "        buy = df.loc[df['side']=='B',:].copy()\n",
    "        for dd in buy['date'].unique():\n",
    "            #import pdb;pdb.set_trace()\n",
    "            tmp = buy.loc[buy['date']==dd,:]\n",
    "            buy.loc[buy['date']==dd,'TimeDiff_back'] = buy.loc[buy['date']==dd,'microsecond'].diff(1).map(lambda x:np.abs(x))\n",
    "            buy.loc[buy['date']==dd,'TimeDiff_frwd'] = buy.loc[buy['date']==dd,'microsecond'].diff(-1).map(lambda x:np.abs(x))\n",
    "            #import pdb;pdb.set_trace()    \n",
    "            buy['TimeDiff_frwd'] = buy['TimeDiff_frwd'].fillna(buy['TimeDiff_frwd'].max())    \n",
    "            buy['TimeDiff_back'] = buy['TimeDiff_back'].fillna(buy['TimeDiff_back'].max())\n",
    "            buy['TimeDiff_min'] = buy.apply(lambda x:min(x['TimeDiff_back'],x['TimeDiff_frwd']),axis=1)\n",
    "\n",
    "        sell = df.loc[df['side']=='S',:].copy()\n",
    "        for dd in sell['date'].unique():\n",
    "            tmp = sell.loc[sell['date']==dd,:]\n",
    "            sell.loc[sell['date']==dd,'TimeDiff_back'] = sell.loc[sell['date']==dd,'microsecond'].diff(1).map(lambda x:np.abs(x))\n",
    "            sell.loc[sell['date']==dd,'TimeDiff_frwd'] = sell.loc[sell['date']==dd,'microsecond'].diff(-1).map(lambda x:np.abs(x))\n",
    "    \n",
    "        sell['TimeDiff_frwd'] = sell['TimeDiff_frwd'].fillna(sell['TimeDiff_frwd'].max())\n",
    "        sell['TimeDiff_back'] = sell['TimeDiff_back'].fillna(sell['TimeDiff_back'].max())\n",
    "        sell['TimeDiff_min'] = sell.apply(lambda x:min(x['TimeDiff_back'],x['TimeDiff_frwd']),axis=1)\n",
    "\n",
    "        newdf = buy.append(sell)\n",
    "        newdf['date'] = newdf['date'].map(lambda x:pd.to_datetime(x))\n",
    "        #newdf = newdf.sort(['date','microsecond'])\n",
    "        df = newdf.sort()\n",
    "        \n",
    "        return df\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class HMM:\n",
    "    def __init__(self,nState,TDFeaSet,featureSet,useAllFea,useDPGMM=True):\n",
    "        '''\n",
    "        recommended value for featureSet=['ewav_back buy/sell']\n",
    "        '''\n",
    "        self.TDFeaSet = TDFeaSet\n",
    "        self.featureSet = featureSet\n",
    "        self.useDPGMM = useDPGMM\n",
    "        self.useAllFea = useAllFea\n",
    "        #self.df = data\n",
    "        self.nState = nState\n",
    "        self.tp = None\n",
    "        self.pi = None\n",
    "        self.TDmodel = []\n",
    "        self.RatioModel = []\n",
    "    \n",
    "    def DefStates(self,df):\n",
    "        '''Define states, return data\n",
    "        '''        \n",
    "        s1 = {'side':'B','IsSpoof':False}\n",
    "        s2 = {'side':'S','IsSpoof':False}\n",
    "        s3 = {'side':'B','IsSpoof':True}\n",
    "        s4 = {'side':'S','IsSpoof':True}\n",
    "        df = df.loc[(df['exec sell']>0)|(df['exec buy']>0),:].copy()\n",
    "        df['state']=0\n",
    "        df.loc[(df['side']=='B')&(df['IsSpoof']==False),'state'] = 0\n",
    "        df.loc[(df['side']=='S')&(df['IsSpoof']==False),'state'] = 1\n",
    "        df.loc[(df['side']=='B')&(df['IsSpoof']==True),'state'] = 2\n",
    "        df.loc[(df['side']=='S')&(df['IsSpoof']==True),'state'] = 3\n",
    "        return df\n",
    "    \n",
    "    def fitmodels(self,data):\n",
    "        ''' fits the emission model for each state\n",
    "        '''\n",
    "        if self.useDPGMM==True:\n",
    "            dpgmm = mixture.DPGMM(n_components=5)\n",
    "        else:\n",
    "            dpgmm = mixture.GMM(n_components=2)\n",
    "        #import pdb;pdb.set_trace()\n",
    "        dpgmm.fit(data)\n",
    "        return dpgmm\n",
    "    \n",
    "    def train(self,df):\n",
    "        self.pi = np.array(df.groupby('state').size()*1.0/len(df))\n",
    "        \n",
    "        df['next state'] = df['state'].shift(-1)    \n",
    "        xx = pd.DataFrame()\n",
    "        for dd in df['date'].unique():\n",
    "            tmp = df.loc[df['date']==dd,:].copy()\n",
    "            tmp = tmp.reset_index(drop=True)\n",
    "            tmp = tmp.ix[0:len(tmp)-2]\n",
    "            if len(tmp)<1:\n",
    "                continue\n",
    "            xx = xx.append(tmp)\n",
    "\n",
    "        gp = xx.groupby(['state','next state','date']).size()\n",
    "        aa = gp.sum(level=[0,1])\n",
    "        bb = gp.sum(level=0)*1.\n",
    "        self.tp = aa/bb\n",
    "\n",
    "        self.TDmodel = []\n",
    "        self.RatioModel = []\n",
    "        for state in range(self.nState):\n",
    "            #import pdb;pdb.set_trace()\n",
    "            td = df.loc[df['state']==state,self.TDFeaSet]\n",
    "            ratio = df.loc[df['state']==state,self.featureSet]\n",
    "        #m1 = fitmodels(td,isGMM=True)\n",
    "        #m2 = fitmodels(ratio,isGMM=True)\n",
    "            m1 = self.fitmodels(td)\n",
    "            m2 = self.fitmodels(ratio)        \n",
    "            self.TDmodel.append(m1)\n",
    "            self.RatioModel.append(m2)\n",
    "        \n",
    "    \n",
    "    def plotDist(self,model):\n",
    "        xx = np.arange(-10,10,0.25)\n",
    "        yy = model.score(xx)\n",
    "        plt.plot(xx,yy)\n",
    "    \n",
    "    def plotDist2(self,model1,model2):\n",
    "        xx = np.arange(-10,10,0.25)\n",
    "        yy1 = model1.score(xx)\n",
    "        yy2 = model2.score(xx)\n",
    "        plt.plot(xx,yy1,'*',xx,yy2,'x')\n",
    "    \n",
    "    def stateEstimator(self,obs):\n",
    "        ''' Estimate the most likely state sequence given the sequence of observations\n",
    "        The data (obs) should be only one day data\n",
    "        '''\n",
    "        nState = self.nState\n",
    "        TDmodel = self.TDmodel\n",
    "        RatioModel = self.RatioModel\n",
    "        tdlist = []\n",
    "        rtlist = []\n",
    "    \n",
    "        for td in TDmodel:\n",
    "            tdlist.append(td.score(obs[self.TDFeaSet]))\n",
    "        for rt in RatioModel:    \n",
    "            rtlist.append(rt.score(obs[self.featureSet]))\n",
    "    \n",
    "        tdprob = np.asmatrix(tdlist)\n",
    "        rtprob = np.asmatrix(rtlist)\n",
    "        if self.useAllFea == True:\n",
    "            distrprob = tdprob + rtprob\n",
    "        else:\n",
    "            distrprob = rtprob\n",
    "        logtp = np.log(tp)\n",
    "        logpi = np.log(pi)\n",
    "    \n",
    "        backtrack = np.ones((nState,len(obs)))*(-1)\n",
    "        pathscore = np.zeros((nState,len(obs)))\n",
    "        \n",
    "        isbuy = obs['side'].map(lambda x:int(x=='B'))\n",
    "        issell = obs['side'].map(lambda x:int(x=='S'))\n",
    "        validState = np.asmatrix([isbuy,issell,isbuy,issell]) # 0 means not valid\n",
    "        dumbval = -1e30\n",
    "    \n",
    "        ttt = np.squeeze(np.asarray(distrprob[:,0])) + logpi\n",
    "        pathscore[:,0] = ttt\n",
    "        for ii in range(nState):\n",
    "            if validState[ii,0]==0:\n",
    "                pathscore[ii,0] = dumbval\n",
    "    \n",
    "        for ii in range(1,len(obs)):\n",
    "            for jj in range(nState):\n",
    "                tmp = logtp[:,jj] + pathscore[:,ii-1]+np.squeeze(np.asarray(distrprob[:,ii]))\n",
    "                pathscore[jj,ii] = max(tmp)\n",
    "                backtrack[jj,ii] = np.argmax(tmp)\n",
    "            for kk in range(nState):\n",
    "                if validState[kk,ii]==0:\n",
    "                    pathscore[kk,ii] = dumbval\n",
    "                    backtrack[kk,ii] = -1\n",
    "        stateSeq = [-1]*len(obs)\n",
    "        stateSeq[len(obs)-1] = np.argmax(pathscore[:,len(obs)-1])\n",
    "        for nn in range(len(obs)-2,-1,-1):\n",
    "            stateSeq[nn] = backtrack[stateSeq[nn+1],nn+1]\n",
    "        return stateSeq\n",
    "    \n",
    "    def stateProb(self,obs):\n",
    "        '''Give the estimate of the probablity of each state at each time instance\n",
    "        '''\n",
    "        tdlist = []\n",
    "        rtlist = []\n",
    "    \n",
    "        nState = self.nState\n",
    "        TDmodel = self.TDmodel\n",
    "        RatioModel = self.RatioModel\n",
    "        \n",
    "        for td in TDmodel:\n",
    "            tdlist.append(td.score(np.array(obs[self.TDFeaSet])))\n",
    "        for rt in RatioModel:    \n",
    "            rtlist.append(rt.score(np.array(obs[self.featureSet])))\n",
    "        \n",
    "        tdprob = np.asmatrix(tdlist)\n",
    "        rtprob = np.asmatrix(rtlist)\n",
    "        if self.useAllFea == True:\n",
    "            distrprob = tdprob + rtprob\n",
    "        else:\n",
    "            distrprob = rtprob        \n",
    "        logtp = np.log(self.tp)\n",
    "        logpi = np.log(self.pi)\n",
    "    \n",
    "        alpha = np.zeros((nState,len(obs)))\n",
    "        beta = np.zeros((nState,len(obs)))\n",
    "    \n",
    "        isbuy = obs['side'].map(lambda x:int(x=='B'))\n",
    "        issell = obs['side'].map(lambda x:int(x=='S'))\n",
    "        validState = np.asmatrix([isbuy,issell,isbuy,issell]) # 0 means not valid\n",
    "        dumb = -1e5 #used to fill for np.log(zero)\n",
    "    \n",
    "        alpha[:,0] = np.squeeze(np.asarray(distrprob[:,0])) + logpi\n",
    "        for ii in range(1,len(obs)):\n",
    "            for kk in range(nState):\n",
    "                if validState[kk,ii]==0:\n",
    "                    alpha[kk,ii] = dumb\n",
    "                else:\n",
    "                    tmp = alpha[:,ii-1] + logtp[:,kk]\n",
    "                    maxtmp = np.max(tmp)\n",
    "                    tmp = tmp - maxtmp\n",
    "                    alpha[kk,ii] = maxtmp + np.log(np.sum(np.exp(tmp))) + distrprob[kk,ii]\n",
    "        \n",
    "        for ii in range(len(obs)-2,-1,-1):\n",
    "            for kk in range(nState):\n",
    "                if validState[kk,ii] == 0:\n",
    "                    beta[kk,ii] = dumb\n",
    "                else:\n",
    "                    tmp = np.asarray(logtp[kk])+beta[:,ii+1]+np.squeeze(np.asarray(distrprob[:,ii+1]))\n",
    "                    maxtmp = np.max(tmp)\n",
    "                    tmp = tmp - maxtmp\n",
    "                    beta[kk,ii] = maxtmp + np.log(np.sum(np.exp(tmp)))\n",
    "            \n",
    "        gamma = alpha+beta # not exactly the gamma\n",
    "        maxgamma = np.max(gamma,0)\n",
    "        gamma = gamma - np.kron(np.reshape(maxgamma,(1,len(obs))),np.ones((nState,1)))\n",
    "        gamma = np.exp(gamma)\n",
    "        sumgamma = np.kron(np.sum(gamma,0),np.ones((nState,1)))\n",
    "        gamma = gamma/sumgamma   \n",
    "        return gamma\n",
    "    \n",
    "    def predict(self,df):\n",
    "        ''' needs more work,better return a dataframe\n",
    "        '''\n",
    "        res = pd.DataFrame()\n",
    "        for xx in df['date'].unique():\n",
    "            data = df.loc[df['date']==xx,:].copy()\n",
    "            prob = self.stateProb(data)\n",
    "            pred = np.argmax(prob,0)\n",
    "            pred_prob=np.max(prob,0)\n",
    "            data['pred'] = pred\n",
    "            data['pred_prob'] = pred_prob\n",
    "            data['predSpoofing'] = data['pred'].map(lambda x:x>1)\n",
    "            res = res.append(data)\n",
    "        return res\n",
    "    \n",
    "    def test(self,df):\n",
    "        all_truth = []\n",
    "        all_score = []\n",
    "\n",
    "        all_pred = []\n",
    "        all_state = []\n",
    "\n",
    "        for xx in df['date'].unique():\n",
    "            data = df.loc[df['date']==xx,:].copy()\n",
    "            prob = self.stateProb(data)\n",
    "            pred = np.argmax(prob,0)\n",
    "            pred_prob=np.max(prob,0)\n",
    "            tmp = (np.array(pred) == np.array(data['state']))\n",
    "            r = sum(tmp)*1.0/len(tmp)\n",
    "            truth = map(lambda x:int(x>1),np.array(data['state']))\n",
    "            score = [y if x>1 else 1-y for x,y in zip(pred,pred_prob)]\n",
    "            auc = metrics.roc_auc_score(truth,score)\n",
    "            all_truth = all_truth + truth\n",
    "            all_score = all_score + score\n",
    "            all_pred = all_pred + list(pred)\n",
    "            all_state = all_state + list(data['state'])\n",
    "    \n",
    "        auc = metrics.roc_auc_score(all_truth,all_score)\n",
    "        tmp = (np.array(all_pred) == np.array(all_state))\n",
    "        rate = sum(tmp)*1./len(tmp)\n",
    "        return auc,rate\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def CrossValidate(df):\n",
    "    ''' randomly split the dataset into 70% train, 30% test\n",
    "            Calculate the AUC and Accuracy\n",
    "    '''\n",
    "    dumbHMM = HMM(nState=4,TDFeaSet=['TimeDiff_frwd','TimeDiff_back'],featureSet=['ewav_back buy/sell'],useAllFea=False,useDPGMM=True) #needs this to add state to the data\n",
    "    df = dumbHMM.DefStates(df)\n",
    "    alldate = []\n",
    "    for xx in df['date'].unique():\n",
    "        tmp = df.loc[df['date']==xx,:]\n",
    "        if len(tmp)>10:\n",
    "            alldate.append(xx)\n",
    "    alldate =  np.array(alldate)\n",
    "\n",
    "    allrate = []\n",
    "    allauc = []\n",
    "    for ii in range(10):\n",
    "        seq = np.random.choice(len(alldate),int(0.7*len(alldate)),replace=False)\n",
    "        traindates = alldate[seq]\n",
    "        traindf = df.loc[df['date'].isin(traindates),:].copy()\n",
    "        testdf = df.loc[df['date'].isin(traindates)==False,:].copy()\n",
    "            #mm = HMM(nState=4,TDFeaSet=['TimeDiff_min'],featureSet=['ewav_back buy/sell'],useAllFea=True,useDPGMM=True)\n",
    "        mm = HMM(nState=4,TDFeaSet=['TimeDiff_frwd','TimeDiff_back'],featureSet=['ewav_back buy/sell'],useAllFea=False,useDPGMM=True)\n",
    "        mm.train(traindf)\n",
    "        auc,rate = mm.test(testdf)\n",
    "        print auc,rate\n",
    "        allrate.append(rate)\n",
    "        allauc.append(auc)\n",
    "\n",
    "    print 'auc={}'.format(np.mean(allauc))\n",
    "    print 'ratio = {}'.format(np.mean(allrate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Predict(df):\n",
    "    traindf = prepareTrainSet()        \n",
    "            #mm = HMM(nState=4,TDFeaSet=['TimeDiff_min'],featureSet=['ewav_back buy/sell'],useAllFea=True,useDPGMM=True)\n",
    "    mm = HMM(nState=4,TDFeaSet=['TimeDiff_frwd','TimeDiff_back'],featureSet=['ewav_back buy/sell'],useAllFea=False,useDPGMM=True)\n",
    "    mm.train(traindf)\n",
    "    df = mm.predict(df)\n",
    "    return df        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.764116777531 0.73595505618\n",
      "0.728381406573 0.750819672131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\caib\\Program\\Python\\Python2_32\\lib\\site-packages\\ipykernel\\__main__.py:45: FutureWarning: sort(....) is deprecated, use sort_index(.....)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-3faf5cf07f6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepareTrainSet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m23\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mCrossValidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-d4ee82cfd5f7>\u001b[0m in \u001b[0;36mCrossValidate\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mmm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHMM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnState\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTDFeaSet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'TimeDiff_frwd'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'TimeDiff_back'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatureSet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ewav_back buy/sell'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0museAllFea\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0museDPGMM\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mmm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraindf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mauc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrate\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mallrate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-848ee118ab12>\u001b[0m in \u001b[0;36mtest\u001b[1;34m(self, df)\u001b[0m\n\u001b[0;32m    229\u001b[0m             \u001b[0mtruth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'state'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0my\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred_prob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m             \u001b[0mauc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtruth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m             \u001b[0mall_truth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_truth\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtruth\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m             \u001b[0mall_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_score\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\caib\\Program\\Python\\Python2_32\\lib\\site-packages\\sklearn\\metrics\\ranking.pyc\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m    251\u001b[0m     return _average_binary_score(\n\u001b[0;32m    252\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m         sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\caib\\Program\\Python\\Python2_32\\lib\\site-packages\\sklearn\\metrics\\base.pyc\u001b[0m in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\caib\\Program\\Python\\Python2_32\\lib\\site-packages\\sklearn\\metrics\\ranking.pyc\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[1;34m(y_true, y_score, sample_weight)\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m             raise ValueError(\"Only one class present in y_true. ROC AUC score \"\n\u001b[0m\u001b[0;32m    245\u001b[0m                              \"is not defined in that case.\")\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "#example 1: cross-validation by randomly split the training set into training set and validating set..\n",
    "df = prepareTrainSet()\n",
    "np.random.seed(23)\n",
    "CrossValidate(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Data cleaning----\n",
      "---- Feature calculation----"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caib\\Python\\Python2-32bit\\lib\\site-packages\\ipykernel\\__main__.py:150: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "C:\\Users\\caib\\Python\\Python2-32bit\\lib\\site-packages\\ipykernel\\__main__.py:179: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "C:\\Users\\caib\\Python\\Python2-32bit\\lib\\site-packages\\numpy\\lib\\function_base.py:3142: RuntimeWarning: Invalid value encountered in median\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Prepare for HMM------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caib\\Python\\Python2-32bit\\lib\\site-packages\\pandas\\core\\indexing.py:426: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\caib\\Python\\Python2-32bit\\lib\\site-packages\\ipykernel\\__main__.py:201: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\caib\\Python\\Python2-32bit\\lib\\site-packages\\ipykernel\\__main__.py:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\caib\\Python\\Python2-32bit\\lib\\site-packages\\ipykernel\\__main__.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\caib\\Python\\Python2-32bit\\lib\\site-packages\\ipykernel\\__main__.py:206: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\caib\\Python\\Python2-32bit\\lib\\site-packages\\ipykernel\\__main__.py:233: FutureWarning: sort(....) is deprecated, use sort_index(.....)\n",
      "C:\\Users\\caib\\Python\\Python2-32bit\\lib\\site-packages\\ipykernel\\__main__.py:45: FutureWarning: sort(....) is deprecated, use sort_index(.....)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-3cf9ed982474>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mallorder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhmmdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocessData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'panl.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhmmdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mallorder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pred'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'pred_prob'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'predSpoofing'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'res_panl.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-39912f1761ba>\u001b[0m in \u001b[0;36mPredict\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mmm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHMM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnState\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTDFeaSet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'TimeDiff_frwd'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'TimeDiff_back'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatureSet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ewav_back buy/sell'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0museAllFea\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0museDPGMM\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mmm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraindf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-848ee118ab12>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, df)\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mxx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m             \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateProb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m             \u001b[0mpred_prob\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-848ee118ab12>\u001b[0m in \u001b[0;36mstateProb\u001b[1;34m(self, obs)\u001b[0m\n\u001b[0;32m    150\u001b[0m             \u001b[0mtdlist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTDFeaSet\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mrt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mRatioModel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m             \u001b[0mrtlist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatureSet\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[0mtdprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtdlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\caib\\Python\\Python2-32bit\\lib\\site-packages\\sklearn\\mixture\\gmm.pyc\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    348\u001b[0m             \u001b[0mLog\u001b[0m \u001b[0mprobabilities\u001b[0m \u001b[0mof\u001b[0m \u001b[0meach\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mpoint\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m         \"\"\"\n\u001b[1;32m--> 350\u001b[1;33m         \u001b[0mlogprob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlogprob\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\caib\\Python\\Python2-32bit\\lib\\site-packages\\sklearn\\mixture\\dpgmm.pyc\u001b[0m in \u001b[0;36mscore_samples\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'gamma_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    255\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\caib\\Python\\Python2-32bit\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    396\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[0;32m    397\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\caib\\Python\\Python2-32bit\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     52\u001b[0m             and not np.isfinite(X).all()):\n\u001b[0;32m     53\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[1;32m---> 54\u001b[1;33m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# example 2: to use HMM to make prediction of new data\n",
    "dp = DataPrep()\n",
    "allorder,hmmdata = dp.processData('panl.csv')\n",
    "\n",
    "res = Predict(hmmdata)\n",
    "tmp = allorder.join(res[['pred','pred_prob','predSpoofing']])\n",
    "tmp.to_csv('res_panl.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
